{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b341cff",
   "metadata": {},
   "source": [
    "## 이진분류에 사용되는 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7290da12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[357,  43],\n",
       "       [ 90, 124]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "confmat = np.array([[357, 43], [90, 124]], dtype=np.int32)\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8c7974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7833876221498371"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (357 + 124) / (357 + 124 + 43 + 90)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9590435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425149700598802"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 124 / (43 + 124)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a94913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5794392523364486"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = 124 / (90+124)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c5bfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6509186351706037"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 2*recall*precision / (recall + precision)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff6bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = (iris.target == 2).astype(np.int32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4e1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c050cef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: \n",
      " [[76  4]\n",
      " [ 2 38]]\n",
      "accuracy: \t 0.95\n",
      "precision: \t 0.9047619047619048\n",
      "recall: \t 0.95\n",
      "f1_score: \t 0.9268292682926829\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "y_pred = cross_val_predict(lr_clf, X_train, y_train, cv=3)\n",
    "print('confusion_matrix: \\n', confusion_matrix( y_train, y_pred))\n",
    "print('accuracy: \\t', accuracy_score(y_train , y_pred))\n",
    "print('precision: \\t', precision_score(y_train , y_pred))\n",
    "print('recall: \\t', recall_score(y_train , y_pred))\n",
    "print('f1_score: \\t', f1_score(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da582e",
   "metadata": {},
   "source": [
    "ROC_AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa507f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_scores = cross_val_predict(lr_clf, X_train, y_train, cv=3, \n",
    "                             method=\"decision_function\")\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Logistic Regression')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74a907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb7fab",
   "metadata": {},
   "source": [
    "# RNN을 이용한 시퀀스 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ca1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (4, 3)\n",
      "y shape:  (4,)\n",
      "x shape:  (4, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# 1. 데이터 준비\n",
    "x = array([[.1, .2, .3], [.2, .3, .4], [.3, .4, .5], [.4, .5, .6]])\n",
    "y = array([.4, .5, .6, .7])\n",
    "\n",
    "print('x shape: ', x.shape)\n",
    "print('y shape: ', y.shape)\n",
    "\n",
    "x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "print('x shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e462b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 3, 8)              320       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                1600      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,065\n",
      "Trainable params: 2,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. LSTM 아키텍쳐(모델) 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, return_sequences=True, input_shape=(3, 1)))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7bc57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6925\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6912\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6906\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6897\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6893\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6887\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6882\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6881\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6873\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6870\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6871\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6867\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6864\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6860\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6859\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6856\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6857\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6853\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.653 - 0s 8ms/step - loss: 0.6854\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6851\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6850\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6850\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6847\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6845\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6844\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6843\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6841\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6839\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6839\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6837\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6839\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6835\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6833\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6832\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6830\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6828\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6826\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6823\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6823\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6820\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6818\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6815\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6813\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6812\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6808\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6805\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6803\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6800\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6796\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6793\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6791\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6787\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6783\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6778\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6775\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6772\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6767\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6763\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6759\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6754\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6749\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6742\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6735\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6729\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6724\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6719\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6712\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6704\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6697\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6694\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6687\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6677\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6671\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6665\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6658: 0s - loss: 0.665\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6652\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6649\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6643\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6640\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6635\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6634\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6631\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6629\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6628\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6627\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6627\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6626\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6626\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6626\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6626\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6626\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6627\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6626\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6626\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6626\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6626\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6626\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6626\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6627\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x212e48a0550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 모델의 컴파일 및 실행\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit(x, y, epochs=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32c83380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88299394]]\n"
     ]
    }
   ],
   "source": [
    "# 4. 추론 (예측)\n",
    "x_input = array([.6, .7, .8]).reshape((1, 3, 1))\n",
    "\n",
    "y_pred = model.predict(x_input)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba83ee",
   "metadata": {},
   "source": [
    "# RNN을 이용한 필기체 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd44c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2293bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc32568",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(28, 28)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94cb809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 64)                23808     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 33,418\n",
      "Trainable params: 33,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b442e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.3927 - accuracy: 0.8725\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 0.1248 - accuracy: 0.9618\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0913 - accuracy: 0.9727\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0724 - accuracy: 0.9779\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0603 - accuracy: 0.9819\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0690 - accuracy: 0.9777\n",
      "[0.0689738318324089, 0.9776999950408936]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76fe4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16baa0",
   "metadata": {},
   "source": [
    "# 한국어를 영어로 번역하는 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a09d47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 1, '당신을': 2, 'i': 3, 'you': 4, 'love': 5, '사랑합니다': 6, '미워합니다': 7, '사랑하지': 8, '않습니다': 9, 'hate': 10, 'do': 11, 'not': 12}\n"
     ]
    }
   ],
   "source": [
    "docs = ['나는 당신을 사랑합니다.', \n",
    "        '나는 당신을 미워합니다.',\n",
    "        '나는 당신을 사랑하지 않습니다.',\n",
    "       'i love you.', \n",
    "       'i hate you.', \n",
    "       'i do not love you.']\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "print(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04824f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 6], [1, 2, 7], [1, 2, 8, 9], [3, 5, 4], [3, 10, 4], [3, 11, 12, 5, 4]]\n"
     ]
    }
   ],
   "source": [
    "x = token.texts_to_sequences(docs)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "82dd9675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  6  0  0]\n",
      " [ 1  2  7  0  0]\n",
      " [ 1  2  8  9  0]\n",
      " [ 3  5  4  0  0]\n",
      " [ 3 10  4  0  0]\n",
      " [ 3 11 12  5  4]]\n"
     ]
    }
   ],
   "source": [
    "pad_x = pad_sequences(x, 5, padding='post') # 시퀀스 앞 부분에 대한 예측이 더 잘되므로 padding으로 뒷쪽을 채움\n",
    "print(pad_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "494f2c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = to_categorical(pad_x)\n",
    "print(one_hot.shape)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c1552314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_39 (LSTM)               (None, 5, 16)             1920      \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 5, 32)             6272      \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 5, 64)             24832     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 5, 32)             2080      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 5, 16)             528       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 5, 13)             221       \n",
      "=================================================================\n",
      "Total params: 35,853\n",
      "Trainable params: 35,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. LSTM 신경망 아키텍쳐 준비\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, return_sequences=True, input_shape=(5, 13)))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c8f3736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5, 13)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "001a0fef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 968us/step - loss: 2.5648 - accuracy: 0.0667\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5608 - accuracy: 0.2000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5567 - accuracy: 0.2667\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5526 - accuracy: 0.2667\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5482 - accuracy: 0.2667\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5434 - accuracy: 0.2667\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5383 - accuracy: 0.2667\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5329 - accuracy: 0.2667\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5270 - accuracy: 0.2667\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5206 - accuracy: 0.2667\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5135 - accuracy: 0.2667\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5059 - accuracy: 0.2667\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4974 - accuracy: 0.2667\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4881 - accuracy: 0.2667\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4778 - accuracy: 0.2667\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4664 - accuracy: 0.2667\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4537 - accuracy: 0.2667\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4395 - accuracy: 0.2667\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4236 - accuracy: 0.2667\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4059 - accuracy: 0.2667\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3862 - accuracy: 0.2667\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3640 - accuracy: 0.2667\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3392 - accuracy: 0.2667\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3115 - accuracy: 0.2667\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.2806 - accuracy: 0.2667\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2464 - accuracy: 0.2667\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2087 - accuracy: 0.2667\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1678 - accuracy: 0.2667\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1242 - accuracy: 0.2667\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0785 - accuracy: 0.2667\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0316 - accuracy: 0.2667\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9849 - accuracy: 0.2667\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9402 - accuracy: 0.2667\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8993 - accuracy: 0.2667\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8637 - accuracy: 0.2667\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8348 - accuracy: 0.2667\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.8135 - accuracy: 0.2667\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7993 - accuracy: 0.2667\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7917 - accuracy: 0.2667\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7885 - accuracy: 0.2667\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7872 - accuracy: 0.2667\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7860 - accuracy: 0.2667\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7833 - accuracy: 0.2667\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7791 - accuracy: 0.2667\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7745 - accuracy: 0.2667\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7693 - accuracy: 0.2667\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7635 - accuracy: 0.2667\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7573 - accuracy: 0.2667\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7510 - accuracy: 0.2667\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7453 - accuracy: 0.2667\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002128DB5EA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7409 - accuracy: 0.2667\n",
      "[1.740921139717102, 0.2666666805744171]\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021295B48D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[4 0 0 0 0]\n",
      " [4 0 0 0 0]\n",
      " [4 0 0 0 0]]\n",
      "you \n",
      "you \n",
      "you \n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "import numpy as np\n",
    "model.fit(one_hot[:3], one_hot[3:], epochs=50)\n",
    "print(model.evaluate(one_hot[:3], one_hot[3:]))\n",
    "predicted = model.predict(one_hot[:3])\n",
    "print(np.argmax(predicted, axis=2))\n",
    "\n",
    "# 추론 결과의 디코딩\n",
    "for arr in np.argmax(predicted, axis=2):\n",
    "    for j in arr:\n",
    "        if j == 0:\n",
    "            continue\n",
    "        else:\n",
    "            print(token.index_word[j], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5326f9d",
   "metadata": {},
   "source": [
    "* 위의 모델은 LSTM 레이어가 3개인 복잡한 아키텍쳐이지만 accuracy가 좋아지지 않음.\n",
    "* 아래와 같이 좀 더 단순하지만 타겟레이블의 모양에 맞추어 정교하게 아키텍쳐 변경\n",
    "    - 최종 출력층의 활성화함수는 sigmoid로 하여 이진분류 케이스로 취급\n",
    "    - 이진분류 케이스이므로 loss는 binary_crossentropy로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "36a6452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_43 (LSTM)               (None, 5, 13)             1404      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 65)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 130)               8580      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 65)                8515      \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 5, 13)             0         \n",
      "=================================================================\n",
      "Total params: 18,499\n",
      "Trainable params: 18,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.0667\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.2667\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6808 - accuracy: 0.4667\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.4667\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6464 - accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5560 - accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2302 - accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1912 - accuracy: 0.7333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.7333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.7333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.7333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.7333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.7333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1279 - accuracy: 0.7333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.7333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.7333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.7333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.7333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.7333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.7333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.8000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.8000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.8000\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.8000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.8000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.8000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.8000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.8000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.8000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.8000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.8000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0596 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 1.0000\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000212FFD02E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 1.0000\n",
      "[0.05319320037961006, 1.0]\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000212ECF4A8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[ 3  5  4  0  0]\n",
      " [ 3 10  4  0  0]\n",
      " [ 3 11 12  5  4]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Flatten, Reshape\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(13, return_sequences=True, input_shape=(5,13)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(130, activation='relu'))\n",
    "model.add(Dense(65, activation='sigmoid'))\n",
    "model.add(Reshape((5,13)))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(one_hot[:3], one_hot[3:], epochs=100)\n",
    "print(model.evaluate(one_hot[:3], one_hot[3:]))\n",
    "predicted = model.predict(one_hot[:3])\n",
    "print(np.argmax(predicted, axis=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d7a86ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you \n",
      "i hate you \n",
      "i do not love you \n"
     ]
    }
   ],
   "source": [
    "# 추론 결과의 디코딩\n",
    "for arr in np.argmax(predicted, axis=2):\n",
    "    for j in arr:\n",
    "        if j == 0:\n",
    "            continue\n",
    "        else:\n",
    "            print(token.index_word[j], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c9a27c",
   "metadata": {},
   "source": [
    "정확한 번역 결과를 얻을 수 있음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
